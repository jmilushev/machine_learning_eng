{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/usr/local/lib/python3.6/site-packages') # For cv2 finding\n",
    "import os, glob, math, cv2, time\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "from keras.utils import np_utils\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folder = 'data/imgs/train'\n",
    "test_folder = 'data/imgs/test'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load the csv file describing the training dataset into a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver_images = pd.read_csv('data/driver_imgs_list.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add path to image and target value series to pandas dataframe describing the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>classname</th>\n",
       "      <th>img</th>\n",
       "      <th>img_path</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_44733.jpg</td>\n",
       "      <td>data/imgs/train/c0/img_44733.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_72999.jpg</td>\n",
       "      <td>data/imgs/train/c0/img_72999.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_25094.jpg</td>\n",
       "      <td>data/imgs/train/c0/img_25094.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_69092.jpg</td>\n",
       "      <td>data/imgs/train/c0/img_69092.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_92629.jpg</td>\n",
       "      <td>data/imgs/train/c0/img_92629.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subject classname            img                          img_path  target\n",
       "0    p002        c0  img_44733.jpg  data/imgs/train/c0/img_44733.jpg       0\n",
       "1    p002        c0  img_72999.jpg  data/imgs/train/c0/img_72999.jpg       0\n",
       "2    p002        c0  img_25094.jpg  data/imgs/train/c0/img_25094.jpg       0\n",
       "3    p002        c0  img_69092.jpg  data/imgs/train/c0/img_69092.jpg       0\n",
       "4    p002        c0  img_92629.jpg  data/imgs/train/c0/img_92629.jpg       0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver_images['img_path'] = driver_images.apply(lambda row: 'data/imgs/train/' + row['classname'] + '/' + row['img'], axis=1)\n",
    "driver_images['target'] = driver_images['classname'].str[1:].astype(int)\n",
    "targets = np_utils.to_categorical(np.array(driver_images['target']), 10)\n",
    "driver_images.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDatasets(driver_images):\n",
    "    \"\"\"converts the target integer values into one hot vector \n",
    "       returns a dataframe containing the image paths and another dataframe with the one-hot target vectors\n",
    "    \"\"\"\n",
    "    image_files = np.array(driver_images['img_path'])\n",
    "    target_categories = np_utils.to_categorical(np.array(driver_images['target']), 10)\n",
    "    return (image_files, target_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitTrainingSetWithShuffle(driver_images, train_part = .8):\n",
    "    \"\"\"\"splits a dataset into a training and validation part in a ratio specified by the method argument train_part,\n",
    "        based on driver, so that all images with a driver reside in just one of the datasets\n",
    "        shuffles both dataframes after the split\n",
    "       returns the two dataframes\n",
    "    \"\"\"\n",
    "\n",
    "    distinct_drivers = driver_images.subject.sort_values().unique()\n",
    "    distinct_drivers_cnt = len(distinct_drivers)\n",
    "    valid_drivers = round(distinct_drivers_cnt * (1 - train_part))\n",
    "   \n",
    "    drivers_valid = distinct_drivers[0:valid_drivers]\n",
    "    drivers_train = distinct_drivers[valid_drivers:]\n",
    "\n",
    "    driver_images_valid = driver_images.loc[driver_images['subject'].isin(drivers_valid)]\n",
    "    driver_images_train = driver_images.loc[driver_images['subject'].isin(drivers_train)]\n",
    "\n",
    "    driver_images_valid = driver_images_valid.sample(frac=1).reset_index(drop=True)\n",
    "    driver_images_train = driver_images_train.sample(frac=1).reset_index(drop=True)\n",
    "    return (driver_images_train, driver_images_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image                  \n",
    "\n",
    "\n",
    "def path_to_tensor(img_path, size):\n",
    "    \"\"\"\n",
    "    loads an image from the specied size and converts into a 4D tensor with shape (1,size,size,3), where\n",
    "    size is the number of pixels of a square image and is passed in as an argument\n",
    "    \"\"\"\n",
    "    # loads RGB image as PIL.Image.Image type\n",
    "    img = image.load_img(img_path, target_size=(size, size))\n",
    "    # convert PIL.Image.Image type to 3D tensor with shape (size, size, 3)\n",
    "    x = image.img_to_array(img)\n",
    "    # convert 3D tensor to 4D tensor with shape (1, size, size, 3) and return 4D tensor\n",
    "    return np.expand_dims(x, axis=0)\n",
    "\n",
    "def paths_to_tensor(img_paths, size=224):\n",
    "    \"\"\"\n",
    "    loads and returns a tensor created after calling path_to_tensor for all images passed in the img_paths dataframe.\n",
    "    \"\"\"\n",
    "    list_of_tensors = [path_to_tensor(img_path, size) for img_path in tqdm(img_paths)]\n",
    "    return np.vstack(list_of_tensors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain the training and validation dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver_images_train, driver_images_valid = splitTrainingSetWithShuffle(driver_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### obtain file paths and target one-hot vectors for the training anf validation sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 18047 training images.\n",
      "There are 4377 validation images.\n",
      "There are 18047 train target.\n",
      "There are 4377 validation targets.\n"
     ]
    }
   ],
   "source": [
    "train_files, train_targets = getDatasets(driver_images_train)\n",
    "valid_files, valid_targets = getDatasets(driver_images_valid)\n",
    "# print statistics about the dataset\n",
    "print('There are %d training images.' % len(train_files))\n",
    "print('There are %d validation images.' % len(valid_files))\n",
    "\n",
    "print('There are %d train target.' % len(train_targets))\n",
    "print('There are %d validation targets.'% len(valid_targets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create the tensors for the training and vaildation datasets and save to storage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18047/18047 [01:47<00:00, 168.62it/s]\n",
      "100%|██████████| 4377/4377 [00:26<00:00, 166.24it/s]\n"
     ]
    }
   ],
   "source": [
    "train_data = paths_to_tensor(train_files, 299).astype('float32')/255\n",
    "valid_data = paths_to_tensor(valid_files, 299).astype('float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('data/train_data_299.txt', train_data)\n",
    "np.save('data/valid_data_299.txt', valid_data)\n",
    "np.save('data/train_targets.txt', train_targets)\n",
    "np.save('data/valid_targets.txt', valid_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18047/18047 [01:36<00:00, 186.99it/s]\n",
      "100%|██████████| 4377/4377 [00:22<00:00, 190.37it/s]\n"
     ]
    }
   ],
   "source": [
    "train_data = paths_to_tensor(train_files, 224).astype('float32')/255\n",
    "valid_data = paths_to_tensor(valid_files, 224).astype('float32')/255\n",
    "np.save('data/train_data_224.txt', train_data)\n",
    "np.save('data/valid_data_224.txt', valid_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare and save a csv file with the image file paths and name of the image to drive for further  processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ntpath\n",
    "\n",
    "path = os.path.join(test_folder, '*.jpg')\n",
    "files = np.sort(glob.glob(path))\n",
    "imgNameArray = []\n",
    "for file in files:\n",
    "    _, fileName = ntpath.split(file) \n",
    "    imgNameArray.append(fileName.split('.')[0])\n",
    "imgNameArray\n",
    "d = {'file_names': files, 'image_names': imgNameArray}    \n",
    "df = pd.DataFrame(data=d)\n",
    "df.to_csv('test_imgs_list.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_test_set_chunk (chunk_size=20000, size=224):\n",
    "    \"\"\"\n",
    "    using the test_imgs_list.csv file, load the image files and convert into a tensor using chnunks of chunk_size\n",
    "    save the resulting tensors of 1000 input images to files.\n",
    "    chunk_size = number of images to use in each chunk\n",
    "    size - size of square image in pixels\n",
    "    \"\"\"\n",
    "    chunk = 1\n",
    "    for gm_chunk in pd.read_csv('data/test_imgs_list.csv', chunksize=chunk_size):\n",
    "        test_data = paths_to_tensor(gm_chunk['file_names'], size).astype('float32')/255\n",
    "        np.save('data/tensors/testing/test_data_' + str(size) + '/chunk_' + str(chunk) + '.txt', test_data)\n",
    "        chunk = chunk + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the pre-processed training set images in batches of 10000 per file (size 299 x 299)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:55<00:00, 181.67it/s]\n",
      "100%|██████████| 10000/10000 [01:01<00:00, 163.47it/s]\n",
      "100%|██████████| 10000/10000 [01:00<00:00, 165.81it/s]\n",
      "100%|██████████| 10000/10000 [00:59<00:00, 168.75it/s]\n",
      "100%|██████████| 10000/10000 [00:58<00:00, 169.99it/s]\n",
      "100%|██████████| 10000/10000 [01:02<00:00, 160.19it/s]\n",
      "100%|██████████| 10000/10000 [01:01<00:00, 163.16it/s]\n",
      "100%|██████████| 9726/9726 [01:00<00:00, 161.27it/s]\n"
     ]
    }
   ],
   "source": [
    "save_test_set_chunk (chunk_size=10000, size=299)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the pre-processed training set images in batches of 10000 per file (size 224 x 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [02:42<00:00, 61.46it/s]\n",
      "100%|██████████| 10000/10000 [02:30<00:00, 66.23it/s]\n",
      "100%|██████████| 10000/10000 [02:39<00:00, 60.79it/s]\n",
      "100%|██████████| 10000/10000 [02:37<00:00, 79.67it/s]\n",
      "100%|██████████| 10000/10000 [02:21<00:00, 70.53it/s]\n",
      "100%|██████████| 10000/10000 [02:16<00:00, 73.00it/s]\n",
      "100%|██████████| 10000/10000 [02:39<00:00, 62.87it/s]\n",
      "100%|██████████| 9726/9726 [02:27<00:00, 65.74it/s]\n"
     ]
    }
   ],
   "source": [
    "save_test_set_chunk (chunk_size=10000, size=224)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
